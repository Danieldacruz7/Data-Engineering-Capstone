{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8wxIYjBu_7O"
      },
      "source": [
        "### Analyse search terms on the e-commerce web server\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgNUSVQDIddi"
      },
      "source": [
        "##### In this assignment you will download the search term data set for the e-commerce web server and run analytic queries on it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKx6l0evIddi",
        "outputId": "4d9ce8cc-9b1f-4fe6-ca5d-baa4137b6cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 28 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 48.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=548d8832bba8990c3c92d0c7d48c28784d5394513e9270bf6b9020be86db77e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n",
            "Collecting pyspark2pmml\n",
            "  Downloading pyspark2pmml-0.5.1.tar.gz (1.6 kB)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.7/dist-packages (from pyspark2pmml) (0.10.9.3)\n",
            "Building wheels for collected packages: pyspark2pmml\n",
            "  Building wheel for pyspark2pmml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark2pmml: filename=pyspark2pmml-0.5.1-py3-none-any.whl size=2418 sha256=3056485987015e765a51075252e5f12838137b9f02a1683fb04f22dae0eb33b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/31/a6/934cee5fbba108e21ebabccb4b79b088cf550455e396447790\n",
            "Successfully built pyspark2pmml\n",
            "Installing collected packages: pyspark2pmml\n",
            "Successfully installed pyspark2pmml-0.5.1\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.7/dist-packages (0.10.9.3)\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ],
      "source": [
        "# Install spark\n",
        "!pip install pyspark\n",
        "!pip install pyspark2pmml\n",
        "!pip install py4j \n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRU71ejbIddk"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_b7viT-Iddl"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fviLXPykIddm"
      },
      "outputs": [],
      "source": [
        "# Creating a spark context class\n",
        "sc = SparkContext()\n",
        "\n",
        "# Creating a spark session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Saving and Loading a SparkML Model\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQcg6l5_Iddm",
        "outputId": "b7de388e-758b-4a2a-8f47-9e4fed8eb834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-06 12:10:13--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/searchterms.csv\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 233457 (228K) [text/csv]\n",
            "Saving to: ‘searchterms.csv’\n",
            "\n",
            "searchterms.csv     100%[===================>] 227.99K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-03-06 12:10:14 (14.1 MB/s) - ‘searchterms.csv’ saved [233457/233457]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download The search term dataset from the below url\n",
        "# https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/searchterms.csv\n",
        "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/searchterms.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAiCDecKIddn",
        "outputId": "2b730115-2926-499d-ed46-106eaa24648f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----+--------------+\n",
            "|day|month|year|    searchterm|\n",
            "+---+-----+----+--------------+\n",
            "| 12|   11|2021| mobile 6 inch|\n",
            "| 12|   11|2021| mobile latest|\n",
            "| 12|   11|2021|   tablet wifi|\n",
            "| 12|   11|2021|laptop 14 inch|\n",
            "| 12|   11|2021|     mobile 5g|\n",
            "| 12|   11|2021| mobile 6 inch|\n",
            "| 12|   11|2021|        laptop|\n",
            "| 12|   11|2021|        laptop|\n",
            "| 12|   11|2021|     mobile 5g|\n",
            "| 12|   11|2021|   tablet wifi|\n",
            "| 12|   11|2021|     mobile 5g|\n",
            "| 12|   11|2021| gaming laptop|\n",
            "| 12|   11|2021|     mobile 5g|\n",
            "| 12|   11|2021|     mobile 5g|\n",
            "| 12|   11|2021| mobile 6 inch|\n",
            "| 12|   11|2021| mobile latest|\n",
            "| 12|   11|2021| mobile 6 inch|\n",
            "| 12|   11|2021|   tablet wifi|\n",
            "| 12|   11|2021|     mobile 5g|\n",
            "| 12|   11|2021|        laptop|\n",
            "+---+-----+----+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the csv into a spark dataframe\n",
        "data_dir = \"searchterms.csv\"\n",
        "df = spark.read.csv(data_dir, header=True)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBcjPEzNIddo",
        "outputId": "dcc36c0d-7ced-4804-c91a-a6d35d2d2840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Rows are: 10000\n",
            "Number of Columns are: 4\n"
          ]
        }
      ],
      "source": [
        "# Print the number of rows and columns\n",
        "# Take a screenshot of the code and name it as shape.jpg\n",
        "row = df.count()\n",
        "   \n",
        "# extracting number of columns from the Dataframe\n",
        "col = len(df.columns)\n",
        "\n",
        "print(f'Number of Rows are: {row}')\n",
        "print(f'Number of Columns are: {col}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_HkqTVtIddp"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import DoubleType\n",
        "df = df.withColumn(\"day\", df.day.cast(DoubleType()))\n",
        "df = df.withColumn(\"month\", df.month.cast(DoubleType()))\n",
        "df = df.withColumn(\"year\", df.year.cast(DoubleType()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qush43L5Idds"
      },
      "outputs": [],
      "source": [
        "# Print the top 5 rows\n",
        "# Take a screenshot of the code and name it as top5rows.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGz8bpLaIdds",
        "outputId": "c3e6d0e8-1e9c-4497-a2d5-7c9fae47f302"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(day=12.0, month=11.0, year=2021.0, searchterm='mobile 6 inch'),\n",
              " Row(day=12.0, month=11.0, year=2021.0, searchterm='mobile latest'),\n",
              " Row(day=12.0, month=11.0, year=2021.0, searchterm='tablet wifi'),\n",
              " Row(day=12.0, month=11.0, year=2021.0, searchterm='laptop 14 inch'),\n",
              " Row(day=12.0, month=11.0, year=2021.0, searchterm='mobile 5g')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23Jbt2URIddt"
      },
      "outputs": [],
      "source": [
        "# Find out the datatype of the column searchterm?\n",
        "# Take a screenshot of the code and name it as datatype.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja7iHV6uIddt",
        "outputId": "a3bc4316-5833-457e-8621-ea0f9847fe26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructField(searchterm,StringType,true)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df.schema[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfKCDStjIddt"
      },
      "outputs": [],
      "source": [
        "# How many times was the term `gaming laptop` searched?\n",
        "# Take a screenshot of the code and name it as gaminglaptop.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aKTpEGNIddu",
        "outputId": "5bca6a98-280d-401b-8b54-3f88d04923e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of times gaming laptop appears in the dataframe: 499\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of times gaming laptop appears in the dataframe: {}\".format(df[df['searchterm']== 'gaming laptop'].count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgxEK_3IIddu"
      },
      "outputs": [],
      "source": [
        "# Print the top 5 most frequently used search terms?\n",
        "# Take a screenshot of the code and name it as top5terms.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbWsLtW_Iddu",
        "outputId": "7abd1d76-1e78-436d-d09c-f7d2288b3c9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+\n",
            "|   searchterm|count|\n",
            "+-------------+-----+\n",
            "|mobile 6 inch| 2312|\n",
            "|    mobile 5g| 2301|\n",
            "|mobile latest| 1327|\n",
            "|       laptop|  935|\n",
            "|  tablet wifi|  896|\n",
            "+-------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.groupBy('searchterm').count().orderBy('count', ascending=False).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g-78vI_Iddu"
      },
      "outputs": [],
      "source": [
        "# The pretrained sales forecasting model is available at  the below url\n",
        "# https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/model.gzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA_hd25wIddv",
        "outputId": "262cbd1e-7436-4c39-e681-d25152758198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-06 12:10:30--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/model.gzip\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1722 (1.7K) [application/gzip]\n",
            "Saving to: ‘model.gzip’\n",
            "\n",
            "model.gzip          100%[===================>]   1.68K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-03-06 12:10:30 (304 MB/s) - ‘model.gzip’ saved [1722/1722]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/model.gzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D95t0tzrIddv",
        "outputId": "5acbff87-b2f9-4e52-e03a-a020691ebdad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sales_prediction.model/\n",
            "sales_prediction.model/metadata/\n",
            "sales_prediction.model/metadata/part-00000\n",
            "sales_prediction.model/metadata/.part-00000.crc\n",
            "sales_prediction.model/metadata/_SUCCESS\n",
            "sales_prediction.model/metadata/._SUCCESS.crc\n",
            "sales_prediction.model/data/\n",
            "sales_prediction.model/data/part-00000-f37d8b09-cd1a-426c-ba90-4047208b011b-c000.snappy.parquet\n",
            "sales_prediction.model/data/.part-00000-f37d8b09-cd1a-426c-ba90-4047208b011b-c000.snappy.parquet.crc\n",
            "sales_prediction.model/data/_SUCCESS\n",
            "sales_prediction.model/data/._SUCCESS.crc\n"
          ]
        }
      ],
      "source": [
        "!tar -zxvf model.gzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxjcGHJgIddv"
      },
      "outputs": [],
      "source": [
        "# Load the sales forecast model.\n",
        "# Take a screenshot of the code and name it as loadmodel.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIcF8ID8Iddv"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.regression import LinearRegressionModel\n",
        "model = LinearRegressionModel.load('sales_prediction.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_bGCP_VIddv"
      },
      "outputs": [],
      "source": [
        "# Using the sales forecast model, predict the sales for the year of 2023.\n",
        "# Take a screenshot of the code and name it as forecast.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYdeiVCdIddw"
      },
      "outputs": [],
      "source": [
        "# This function converts a scalar number into a dataframe that can be used by the model to predict.\n",
        "def predict(year):\n",
        "    assembler = VectorAssembler(inputCols=[\"year\"],outputCol=\"features\")\n",
        "    data = [[year,0]]\n",
        "    columns = [\"year\", \"sales\"]\n",
        "    _ = spark.createDataFrame(data, columns)\n",
        "    __ = assembler.transform(_).select('features','sales')\n",
        "    predictions = model.transform(__)\n",
        "    predictions.select('prediction').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wfsX6t7Iddw",
        "outputId": "b7d7a048-e711-44ad-bf60-81fa8a028f32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|        prediction|\n",
            "+------------------+\n",
            "|176.14285712605306|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(2023)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Spark_MLOps.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}